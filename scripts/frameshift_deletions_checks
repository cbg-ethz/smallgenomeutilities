#!/usr/bin/env python3

import pysam
import pysamstats
import numpy as np
import pandas as pd
from io import StringIO
from Bio import SeqIO
from Bio import AlignIO
from Bio.Align.Applications import MafftCommandline
from BCBio import GFF
import operator
import argparse
import re
import os
import tempfile
import sys



def str2bool(v):
    if isinstance(v, bool):
        return v
    if v.lower() in ('yes', 'true', 't', 'y', '1'):
        return True
    elif v.lower() in ('no', 'false', 'f', 'n', '0'):
        return False
    else:
        raise argparse.ArgumentTypeError('Boolean value expected.')

def parse_args():
    """ Set up the parsing of command-line arguments """

    # keep lines in epilog ; but keep the defaults in the list
    class Formatter(argparse.ArgumentDefaultsHelpFormatter, argparse.RawDescriptionHelpFormatter): pass

    parser = argparse.ArgumentParser(
        description="Produces a report about frameshifting indels in a consensus sequences",
        epilog=u"""columns signification:
	[gene_region]: Gene in which the deletion is found according to -g argument;
	[reads_all]: Total number of reads covering the indel;
	[reads_fwd]: Total nubmer of forward reads covering the indel;
	[reads_rev]: Total nubmer of reverse reads covering the indel;
	[deletions/insertions]: Number of reads supporting the deletion/insertion;
	[freq_del/freq_insert]: Fraction of reads supporting the deletion/insertion;
	[matches_ref]: number of reads that matche with the reference base;
	[pos_critical_inserts]: Start positions of insertions in the same gene_region that occur in > 40% of reads;
	[pos_critical_dels]: Start positions of deletions in the same gene_region that occur in > 40% of reads;
	[homopolymeric]: True if either around the start or end position of the deletion three bases are the same, which may have caused the polymerase to skip during reverse transcription of viral RNA to cDNA, e.g. AATAG;
	[ref_base]: base in the reference genome
	[indel_position_english]: english sentence describing the indel
	[indel_diagnosis]: english sentence with the indel diagnosis""",
        formatter_class=Formatter)
    requiredNamed = parser.add_argument_group('required named arguments')
    requiredNamed.add_argument(
        "-i", "--input", required=True, metavar='BAM', dest='bamfile',
        help="Input BAM file, aligned against the reference"
    )
    requiredNamed.add_argument(
        "-c", "--consensus", required=True, metavar='FASTA', dest='ref_majority_dels', type=str,
        help="Fasta file containing the ref_majority_dels consensus sequence"
    )
    requiredNamed.add_argument(
        "-f", "--reference", required=True, metavar='FASTA', dest='reference', type=str,
        help="Fasta file containing the reference sequence to compare against"
    )
    requiredNamed.add_argument(
        "-g", "--genes", required=True, metavar='GFF', dest='genes_gff', type=str,
        help="GFF file listing genes positions on the reference sequence"
    )
    parser.add_argument(
        "-0", "--zero-based", required=False, dest='based', action='store_const', const=0, default=1,
        help="Use 0-based (python) instead of 1-based (standard) seq positions"
    )
    parser.add_argument(
        "-o", "--output", required=False, default=os.path.join(os.getcwd(), 'frameshift_deletions_check.tsv'),
        metavar='TSV', dest='outfile', help="Output file"
    )
    parser.add_argument(
        "-E", "--no-english", dest='english', action='store_false')
    parser.add_argument(
        "-e", "--english", required=False, type=str2bool, nargs='?', const=True, dest='english',
        help="If True writes english summary diagnosis."
    )
    parser.set_defaults(english=True)
    return parser.parse_args()

def check_homopolyeric(variation_info, position, gap_length, indel_type):
    '''
    return homopolyeric == True if either around the start_position or the end_position
    between the two neighbors 3 are of the same base, eg. AATAG
    '''

    # NOTE insertions are in reference space, so the end of the insetion is at [position + 1]
    # whereas deletions' end is at [ position + lenght -1 ]
    for p in [ position-1, position+(1 if indel_type == 'insertion' else gap_length)-1 ]:
        nuc_list =[]
        # list index for [position +/- 2]
        # also only pick covered psotions (e.g.: "nnnnATTCG-Cnnn" - 'C' is alone, there no reads on position+2)
        idx_pos = np.where(np.logical_and(variation_info.pos>=p-2, variation_info.pos<=p+2))[0]
        if idx_pos.size==0:
            # really broken alignment
            print(f"Warning no reads around {ref_id}:{position-2}:{position+2} for homopolyeric ?!", file=sys.stderr)
            continue

        # count all the listed
        nuc_list=[variation_info[p].ref[0] for p in idx_pos]
        uni_list = np.unique(nuc_list, return_counts=True)
        if np.max(uni_list[1])>2:
            return 1

    return 0

def parse_gff(genes_gff):
    """
    Return a gene_list suitable for get_gene_at_position
    """
    if genes_gff:
        with open(genes_gff) as gf:
            return [ (record.id, int(feature.location.start), int(feature.location.end), feature.qualifiers.get('Name', [feature.id])[0]) for record in GFF.parse(gf) for feature in record.features if feature.type == 'gene' ]
    return None

def get_gene_at_position(gene_list, ref_id, position):
    """
    Return gene and gene-region-interval the position belongs to.
    This is only valid for SARS-CoV2.
    """
    for gene in gene_list:
        if (gene[0] == ref_id) and (position in range(gene[1],gene[2])):
            return gene

    return (ref_id, position-10, position+10, '-')

def check_indels_gene_region(gene_reg_load_variation, curr_pos, gap_length, indel_type, region_start, region_end, based):
    """
    check if there are some indels in the gene-region-interval(*) that occur in
    more than 40% of the reads. If so, returns the position of those insertions.
    ---
    (*): or at least the part that got coverage
    """

    # clip the request to position for which we have information. Worse-case scenario: begins or ends with the indel
    i_start = np.where(gene_reg_load_variation.pos >=region_start)[0][0]
    i_end = np.where(gene_reg_load_variation.pos <=region_end)[0][-1]

    # NOTE the index of these scrutures will be same across all,
    # BUT will not correspond to the actual position
    indel_pos = gene_reg_load_variation.pos[i_start:i_end]
    reads_all = gene_reg_load_variation.reads_all[i_start:i_end]
    inserts= gene_reg_load_variation.insertions[i_start:i_end]
    dels= gene_reg_load_variation.deletions[i_start:i_end]

    # NOTE When looking for an insert:
    # - we will not list the insert *itself*
    # - we *will* list overlapping *deletions* on other reads.
    # And vice-versa for deletions.
    critical_inserts = [indel_pos[i]+based for i,x in enumerate(inserts) if (x > 0.4*reads_all[i]) and (indel_type=='deletion' or indel_pos[i]!=curr_pos)]
    critical_dels = [indel_pos[i]+based for i,x in enumerate(dels) if (x > 0.4*reads_all[i]) and ((indel_type=='insertion') or (indel_pos[i] not in range(curr_pos, curr_pos+gap_length)))]

    return critical_inserts, critical_dels

def ranges(nums):
    """
    auxiliary function for list_frameshift_dels().
    Input is a list of numbers
    return ranges that are covered by those numbers,
    e.g. [1,2,3,10]--> [(1,3),(10,10)]
    """
    nums = sorted(set(nums))
    gaps = [[s, e] for s, e in zip(nums, nums[1:]) if s+1 < e]
    edges = iter(nums[:1] + sum(gaps, []) + nums[-1:])
    return list(zip(edges, edges))

def len_del(item_range):
    """
    auxiliary function for list_frameshift_dels().
    computing the lenght of item_range,
    """
    return item_range[1]- item_range[0]+1

def list_all_inserts(aligned_seqs):
    '''
    returns list with starting position of _all_ inserts and their resepective length as tuple: (start_pos, length)
    '''
    pos_length_list = []
    for reference_seq, consensus_seq in zip(*[iter(aligned_seqs)]*2):
        insert_pos = [i for i,x in enumerate(reference_seq.seq) if x =="-"]

        for item_range in ranges(insert_pos):
            pos_length_list.append([item_range[0],len_del(item_range), reference_seq.id, consensus_seq.id, 'insertion'])

    return pos_length_list

def list_all_dels(aligned_seqs):
    '''
    returns list with starting position of _all_  dels and their resepective length as tuple: (start_pos, length)
    '''
    pos_length_list = []
    for reference_seq, consensus_seq in zip(*[iter(aligned_seqs)]*2):
        del_pos = [i for i,x in enumerate(consensus_seq.seq) if x =="-"]

        for item_range in ranges(del_pos):
            pos_length_list.append([item_range[0],len_del(item_range),reference_seq.id, consensus_seq.id, 'deletion'])

    return pos_length_list

def align(reference, consensus):
    """
    we rely on a MAFFT alignment, in order to:
    - detect deletions in consensuses from callers that do not mark them
      (e.g.: bcftools without the `--mark-dels '-'` option)
    - detect insertions in the consensus
        (will appear as deletions *in the reference*)
    """


    all_align=[]

    # Loop through pairs to avoid MAFFT aligning different unrelated segments
    for seq_record, ref_record in zip(SeqIO.parse(consensus, "fasta"), SeqIO.parse(reference, "fasta")):
        # HACK assume seq_record have same order as ref_record
        # TODO test to multi-segemented viruses before the next flu pandemic
        print(f"{seq_record.id} mapped to {ref_record.id}")

        if (align.rx_only_n.match(str(seq_record.seq))):
            print(f"Warning: {seq_record.id} contains only <N>s", file=sys.stderr)
            # BUG MAFFT has a bug where if such a only-<N>s sequence is given as an argument, it will generate an alignement offset by 1 bogus gap at each end:
            # > Alignment with 2 rows and 29904 columns
            # > attaaaggtttataccttcccaggtaacaaaccaaccaactttc...aa- NC_045512.2
            # > -nnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnn...nnn 100100_31_C02-20200508_J3GT6
            # these bogus gaps are not supported by any reads and break analyse_position()
            # we *must* not call MAFFT
            continue

        data=[ref_record, seq_record]

        # NOTE this also handles properly TMPDIR on clusters
        with tempfile.NamedTemporaryFile() as tmp:
            # Open the file for writing.
            with open(tmp.name, 'w') as f:
                SeqIO.write(data, tmp.name, "fasta")
                f.seek(0)

            mafft_cline = MafftCommandline(input=tmp.name)
            stdout, stderr = mafft_cline()
            if (len(stderr)>0):
                print(mafft_cline, ":", file=sys.stderr)
                print(stderr, file=sys.stderr)
            all_align += AlignIO.read(StringIO(stdout), "fasta")

    return all_align
# static re: only compile it once
align.rx_only_n=re.compile("^[Nn]+$")

def check_dels_gene_region(frameshift_deletions, region_start, region_end, position):
    """
    Check for deletions that are also in the consensus in this gene region.
    """
    critical_pos= []
    for pos1 in frameshift_deletions:
        if pos1[0] in range(region_start, region_end):
            if pos1[0]!=position:
                critical_pos.append(pos1[0])

    return critical_pos

def correct_positions(list_dels,list_inserts):
    '''
    Insertions shift the positions --> shift back to reference seq space
    Correct to zero-based (we need this for pysamstats).
    '''
    # correct deletions shifted due to insertions occuring before
    for count, insert in enumerate(list_inserts):
        for deletion in list_dels:
            if deletion[0] > insert[0]:
                deletion[0]-=insert[1]
    # shift insertions due to insertions occuring before
    for count, insert in enumerate(list_inserts):
        for j in range(count+1, len(list_inserts)):
            if list_inserts[j][0] > insert[0]:
                list_inserts[j][0]-=insert[1]
    # shift inseritions to zero-based space
    for j in range(len(list_inserts)):
        list_inserts[j][0]-=1

    corrected_insert = list_inserts
    corrected_dels =list_dels

    return corrected_insert, corrected_dels

def write_english_summary(df_temp):
    """
    Add summary deletion_diagnosis column to deletion data table
    """
    indel_position_english =[]
    deletion_diagnosis =[]
    for iter, row in df_temp.iterrows():
        # description of the indels themselves
        indel_type = None
        if row['INDEL']=='deletion':
            indel_type = 'Gap'
        elif row['INDEL']=='insertion':
            indel_type = 'Insertion'
        else:
            raise ValueError("Bad indel type", row['INDEL'])
        indel_pos_temp = f"{indel_type} of {row['length']} nucleotide(s) found at refpos {row['start_position']}"
        indel_position_english.append(str(indel_pos_temp))

         # diagnosis of the indel
        if indel_type == 'Gap':
            name = 'deletion'
            fwdc = row['freq_del_fwd']
            revc = row['freq_del_rev']
        elif indel_type == 'Insertion':
            name = 'insertion'
            fwdc = row['freq_insert_fwd']
            revc = row['freq_insert_rev']
        else:
            # Throw some 'internal error' exception
            raise ValueError("Bad indel type", row['INDEL'])

        if (fwdc > 0.5 and revc > 0.5):
            support_status = f"{name} supported by majority of fwd and rev reads"
        elif (fwdc > 0.5 and row['reads_rev']== 0) or (revc > 0.5 and row['reads_fwd'] == 0):
            support_status = f"only fwd or rev reads available, {name} supported by the majority of them"
        elif (fwdc > 0.5) or (revc > 0.5):
            support_status = f"{name} supported by majority of fwd or rev reads"
        elif (fwdc >= 0.05 and row['reads_rev']== 0) or (revc >= 0.05 and row['reads_fwd'] == 0):
            support_status = f"only fwd or rev reads available, {name} supported by the minority of them [5%-50%["
        elif (fwdc >= 0.05) or (revc >= 0.05):
            support_status = f"{name} supported by minority of fwd or rev reads [5%-50%]"
        else:
            support_status = f"{name} not supported (covered by less than 5% of fwd and rev reads)"

        homopolymeric_status="homopolymeric" if row['homopolymeric']==1 else None
        pos_critical_status="neighboring indels may restore reading frame" if (row['pos_critical_dels'] != []) or (row['pos_critical_inserts'] != []) else None

        text_row='; '.join([s for s in [support_status, homopolymeric_status, pos_critical_status] if s])
        deletion_diagnosis.append(text_row)

    df_temp['indel_position_english']=indel_position_english
    df_temp['indel_diagnosis']=deletion_diagnosis
    return df_temp

def analyse_position(bamfile, reference, ref_id, position, gap_length, indel_type, gene_list, cons_id='', based=1):
    """
    gather information for current frameshift position.
    """
    gene_region= get_gene_at_position(gene_list, ref_id, position)
    region_start = max(gene_region[1], 0)
    region_end = gene_region[2]

    if (analyse_position.ref_id == ref_id and analyse_position.region_start==region_start and analyse_position.region_end==region_end):
        # cache hit! no need to reparse the BAM file!
        variation_info = analyse_position.indels_gene_reg
    else:
        analyse_position.indels_gene_reg = variation_info = pysamstats.load_variation_strand(bamfile, fafile=reference,
                                     chrom=ref_id,
                                     start=region_start, end=region_end)
        # NOTE the region of interest covers the position anyway, so we can re-use the cache of the whole region stats
                                     #start=position, end=position+gap_length)
        analyse_position.ref_id=ref_id
        analyse_position.region_start=region_start
        analyse_position.region_end=region_end


    idx_pos = np.where(variation_info.pos==position)
    if(idx_pos[0].size==0):
        # see MAFFT's BUG mentionned in align()
        print(f"Warning no read mapping to {ref_id}:{position}:+{gap_length}", file=sys.stderr)
        return { } # empty dict

    reads_all = variation_info[idx_pos].reads_all[0]
    reads_fwd = variation_info[idx_pos].reads_fwd[0]
    reads_rev = variation_info[idx_pos].reads_rev[0]

    deletions = variation_info[idx_pos].deletions[0]
    freq_del = deletions/reads_all
    deletions_fwd = variation_info[idx_pos].deletions_fwd[0]
    freq_del_fwd = deletions_fwd/reads_fwd if reads_fwd else 0
    deletions_rev = variation_info[idx_pos].deletions_rev[0]
    freq_del_rev = deletions_rev/reads_rev if reads_rev else 0

    insertions = variation_info[idx_pos].insertions[0]
    freq_insert = insertions/reads_all
    insertions_fwd = variation_info[idx_pos].insertions_fwd[0]
    freq_insert_fwd = insertions_fwd/reads_fwd if reads_fwd else 0
    insertions_rev = variation_info[idx_pos].insertions_rev[0]
    freq_insert_rev = insertions_rev/reads_rev if reads_rev else 0

    # NOTE the region of interest covers the position anyway, so we can re-use the whole region stats
    indels_gene_reg = analyse_position.indels_gene_reg
    critical_inserts, critical_dels= check_indels_gene_region(indels_gene_reg,position, gap_length, indel_type,
                                                    region_start, region_end, based)

    homopolyeric = check_homopolyeric(variation_info, position, gap_length, indel_type)

    dict = {'ref_id': ref_id,
            'start_position': position+based,
            'length': gap_length,
            'INDEL': indel_type,
            'gene_region':gene_region[3],
            'reads_all': reads_all,
            'reads_fwd': reads_fwd,
            'reads_rev': reads_rev,
            'deletions': deletions,
            'freq_del': freq_del,
            'freq_del_fwd': freq_del_fwd ,
            'freq_del_rev':freq_del_rev,
            'deletions_fwd': deletions_fwd,
            'deletions_rev': deletions_rev,
            'insertions': insertions,
            'freq_insert': freq_insert,
            'freq_insert_fwd': freq_insert_fwd ,
            'freq_insert_rev':freq_insert_rev,
            'insertions_fwd': insertions_fwd,
            'insertions_rev': insertions_rev,
            'matches_ref': variation_info[idx_pos].matches[0],
            'pos_critical_inserts': critical_inserts,
            'pos_critical_dels': critical_dels,
            'homopolymeric': homopolyeric,
            'ref_base': variation_info[idx_pos].ref[0],
            'cons_id': cons_id,
           }

    return dict
# keep a static cache between calls
analyse_position.ref_id=None
analyse_position.region_start=None
analyse_position.region_end=None
analyse_position.indels_gene_reg=None

def main():

    args = parse_args()
    bamfile = args.bamfile	    # e.g.: 'REF_aln_410130_171220eg29_H5.bam'
    reference = args.reference	# e.g.: '../references/NC_045512.2.fasta'
    consensus = args.ref_majority_dels	# e.g.: 'ref_majority_dels.fasta'

    gene_list = parse_gff(args.genes_gff) # e.g.: 'Genes_NC_045512.2.GFF3'

    df = pd.DataFrame(columns=('ref_id','start_position','length','INDEL','gene_region',
                                'reads_all','reads_fwd','reads_rev',
                                'deletions','freq_del','freq_del_fwd','freq_del_rev',
                                'deletions_fwd','deletions_rev',
                                'insertions','freq_insert','freq_insert_fwd','freq_insert_rev',
                                'insertions_fwd','insertions_rev',
                                'matches_ref','pos_critical_inserts','pos_critical_dels',
                                'homopolymeric','ref_base','cons_id'))


    align_seqs = align(reference, consensus)
    if (len(align_seqs)==0):
        print("Warning: no usable alignment", file=sys.stderr)
    elif (len(align_seqs)%2!=0):
        print(f"Fatal error: there are {len(align_seqs)} alignements (odd), they should be in pairs (even)!", file=sys.stderr)
        sys.exit(1)
    else:
        align_dels= list_all_dels(align_seqs)
        align_inserts= list_all_inserts(align_seqs)

        # convert coordinate from pair-alignment space to reference-space
        corrected_insert, corrected_dels = correct_positions(align_dels,align_inserts)

        # sort by ref_id, then by position to optimize cache hits in analyse_position
        for pos in sorted(corrected_dels+corrected_insert, key=operator.itemgetter(2,0)):
            ref_id = pos[2]
            position = int(pos[0])
            gap_length = int(pos[1])
            cons_id = pos[3]
            indel_type = pos[4]
            if gap_length%3==0:
                # only frameshift insertions , i.e. insert lenght not dividible by 3
                continue
            pos_dict = analyse_position(bamfile, reference, ref_id, position, gap_length,indel_type,
                                        gene_list,cons_id, based=args.based)
            if (len(pos_dict)==0):
                # skip when no information extracted
                continue
            df = df.append(pos_dict, ignore_index=True)

    if args.english==True:
        print("adding english language")
        df= write_english_summary(df)


    df.to_csv(args.outfile, sep='\t') # write to tsv-file

if __name__ == '__main__':
    main()
